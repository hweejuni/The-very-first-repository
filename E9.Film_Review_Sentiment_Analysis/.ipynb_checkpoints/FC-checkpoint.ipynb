{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-23485464c763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# list 형태의 sentences는 numpy array로 변환되어야 딥러닝 레이어의 입력이 될 수 있습니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mraw_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_encoded_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_non_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_convert_non_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0;31m# `SparseTensors` can't be converted to `Tensor`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_non_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1281\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m    261\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 262\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "# 아래 코드는 그대로 실행하시면 에러가 발생할 것입니다. \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 위 그림과 같이 4차원의 워드벡터를 가정합니다. \n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다. \n",
    "# list 형태의 sentences는 numpy array로 변환되어야 딥러닝 레이어의 입력이 될 수 있습니다.\n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.00352578  0.00335013 -0.01379466 -0.00441816]\n",
      "  [-0.03255465 -0.01700375 -0.02822323 -0.0093087 ]\n",
      "  [-0.02186581  0.01508064 -0.00080389 -0.03978688]\n",
      "  [-0.03762106  0.04984539  0.04869875  0.00051796]\n",
      "  [ 0.00608573  0.0085599   0.03783837  0.01314322]]\n",
      "\n",
      " [[ 0.00352578  0.00335013 -0.01379466 -0.00441816]\n",
      "  [-0.03255465 -0.01700375 -0.02822323 -0.0093087 ]\n",
      "  [-0.01177659 -0.01886578 -0.01782409 -0.04706441]\n",
      "  [ 0.00862957 -0.04607552  0.04818649  0.03717801]\n",
      "  [ 0.00608573  0.0085599   0.03783837  0.01314322]]\n",
      "\n",
      " [[ 0.00352578  0.00335013 -0.01379466 -0.00441816]\n",
      "  [ 0.00706457  0.01863216  0.00876762 -0.02409855]\n",
      "  [-0.03255465 -0.01700375 -0.02822323 -0.0093087 ]\n",
      "  [-0.02186581  0.01508064 -0.00080389 -0.03978688]\n",
      "  [-0.01810278 -0.02979332  0.01313328  0.03303644]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Should it be RNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# IMDB 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word[0] = \"<PAD>\"\n",
    "index_to_word[1] = \"<BOS>\"\n",
    "index_to_word[2] = \"<UNK>\"\n",
    "index_to_word[3] = \"<UNUSED>\"\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "30/30 [==============================] - 6s 198ms/step - loss: 0.6915 - accuracy: 0.5317 - val_loss: 0.6881 - val_accuracy: 0.5704\n",
      "Epoch 2/30\n",
      "30/30 [==============================] - 5s 181ms/step - loss: 0.6737 - accuracy: 0.6516 - val_loss: 0.6486 - val_accuracy: 0.6754\n",
      "Epoch 3/30\n",
      "30/30 [==============================] - 5s 175ms/step - loss: 0.5527 - accuracy: 0.7872 - val_loss: 0.6134 - val_accuracy: 0.7000\n",
      "Epoch 4/30\n",
      "30/30 [==============================] - 5s 174ms/step - loss: 0.4729 - accuracy: 0.8326 - val_loss: 0.4380 - val_accuracy: 0.8388\n",
      "Epoch 5/30\n",
      "30/30 [==============================] - 5s 174ms/step - loss: 0.3553 - accuracy: 0.8827 - val_loss: 0.3762 - val_accuracy: 0.8600\n",
      "Epoch 6/30\n",
      "30/30 [==============================] - 6s 185ms/step - loss: 0.2812 - accuracy: 0.9133 - val_loss: 0.3495 - val_accuracy: 0.8603\n",
      "Epoch 7/30\n",
      "30/30 [==============================] - 5s 177ms/step - loss: 0.2275 - accuracy: 0.9329 - val_loss: 0.3446 - val_accuracy: 0.8655\n",
      "Epoch 8/30\n",
      "30/30 [==============================] - 5s 180ms/step - loss: 0.1885 - accuracy: 0.9455 - val_loss: 0.3385 - val_accuracy: 0.8624\n",
      "Epoch 9/30\n",
      "30/30 [==============================] - 5s 176ms/step - loss: 0.1578 - accuracy: 0.9577 - val_loss: 0.3423 - val_accuracy: 0.8691\n",
      "Epoch 10/30\n",
      "30/30 [==============================] - 5s 178ms/step - loss: 0.1356 - accuracy: 0.9646 - val_loss: 0.3573 - val_accuracy: 0.8699\n",
      "Epoch 11/30\n",
      "30/30 [==============================] - 5s 176ms/step - loss: 0.1190 - accuracy: 0.9693 - val_loss: 0.3700 - val_accuracy: 0.8651\n",
      "Epoch 12/30\n",
      "30/30 [==============================] - 5s 177ms/step - loss: 0.1061 - accuracy: 0.9741 - val_loss: 0.3869 - val_accuracy: 0.8635\n",
      "Epoch 13/30\n",
      "30/30 [==============================] - 5s 177ms/step - loss: 0.0916 - accuracy: 0.9782 - val_loss: 0.4000 - val_accuracy: 0.8632\n",
      "Epoch 14/30\n",
      "30/30 [==============================] - 5s 178ms/step - loss: 0.0825 - accuracy: 0.9815 - val_loss: 0.4206 - val_accuracy: 0.8577\n",
      "Epoch 15/30\n",
      "30/30 [==============================] - 5s 178ms/step - loss: 0.0725 - accuracy: 0.9847 - val_loss: 0.4378 - val_accuracy: 0.8561\n",
      "Epoch 16/30\n",
      "30/30 [==============================] - 5s 177ms/step - loss: 0.0650 - accuracy: 0.9865 - val_loss: 0.4546 - val_accuracy: 0.8560\n",
      "Epoch 17/30\n",
      "30/30 [==============================] - 5s 175ms/step - loss: 0.0591 - accuracy: 0.9876 - val_loss: 0.4793 - val_accuracy: 0.8532\n",
      "Epoch 18/30\n",
      "30/30 [==============================] - 5s 176ms/step - loss: 0.0564 - accuracy: 0.9881 - val_loss: 0.4758 - val_accuracy: 0.8530\n",
      "Epoch 19/30\n",
      "30/30 [==============================] - 5s 177ms/step - loss: 0.0528 - accuracy: 0.9895 - val_loss: 0.5186 - val_accuracy: 0.8510\n",
      "Epoch 20/30\n",
      "30/30 [==============================] - 5s 176ms/step - loss: 0.0495 - accuracy: 0.9898 - val_loss: 0.5066 - val_accuracy: 0.8546\n",
      "Epoch 21/30\n",
      "30/30 [==============================] - 5s 176ms/step - loss: 0.0458 - accuracy: 0.9909 - val_loss: 0.5184 - val_accuracy: 0.8541\n",
      "Epoch 22/30\n",
      "30/30 [==============================] - 5s 175ms/step - loss: 0.0535 - accuracy: 0.9877 - val_loss: 0.5163 - val_accuracy: 0.8547\n",
      "Epoch 23/30\n",
      "30/30 [==============================] - 5s 176ms/step - loss: 0.0455 - accuracy: 0.9896 - val_loss: 0.5190 - val_accuracy: 0.8557\n",
      "Epoch 24/30\n",
      "30/30 [==============================] - 5s 177ms/step - loss: 0.0390 - accuracy: 0.9923 - val_loss: 0.5140 - val_accuracy: 0.8515\n",
      "Epoch 25/30\n",
      "30/30 [==============================] - 5s 176ms/step - loss: 0.0340 - accuracy: 0.9939 - val_loss: 0.5447 - val_accuracy: 0.8522\n",
      "Epoch 26/30\n",
      "30/30 [==============================] - 5s 176ms/step - loss: 0.0293 - accuracy: 0.9950 - val_loss: 0.5589 - val_accuracy: 0.8519\n",
      "Epoch 27/30\n",
      "30/30 [==============================] - 5s 175ms/step - loss: 0.0268 - accuracy: 0.9955 - val_loss: 0.5848 - val_accuracy: 0.8526\n",
      "Epoch 28/30\n",
      "30/30 [==============================] - 5s 177ms/step - loss: 0.0250 - accuracy: 0.9957 - val_loss: 0.5892 - val_accuracy: 0.8521\n",
      "Epoch 29/30\n",
      "30/30 [==============================] - 5s 176ms/step - loss: 0.0339 - accuracy: 0.9926 - val_loss: 0.6274 - val_accuracy: 0.8480\n",
      "Epoch 30/30\n",
      "30/30 [==============================] - 5s 176ms/step - loss: 0.0417 - accuracy: 0.9885 - val_loss: 0.5361 - val_accuracy: 0.8484\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=30  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 14s - loss: 0.5722 - accuracy: 0.8403\n",
      "[0.5722349882125854, 0.8403199911117554]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01688392,  0.05218362, -0.04018296, -0.02011499,  0.00336474,\n",
       "       -0.05254532,  0.03990914,  0.03593897,  0.04712682, -0.03477805,\n",
       "        0.0052436 , -0.05051265, -0.00681261,  0.00487261, -0.05441365,\n",
       "        0.0114319 ], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('couch', 0.9500424861907959),\n",
       " ('anticipated', 0.9477282762527466),\n",
       " ('often', 0.9455941915512085),\n",
       " ('ride', 0.9432206153869629),\n",
       " ('sings', 0.937906801700592),\n",
       " ('fascinating', 0.9366618394851685),\n",
       " ('ages', 0.9316500425338745),\n",
       " ('networks', 0.9279906749725342),\n",
       " (\"ol'\", 0.9264562129974365),\n",
       " ('warmth', 0.9251642823219299)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loved', 0.6907792091369629),\n",
       " ('adore', 0.6816873550415039),\n",
       " ('loves', 0.661863386631012),\n",
       " ('passion', 0.6100709438323975),\n",
       " ('hate', 0.600395679473877),\n",
       " ('loving', 0.5886635780334473),\n",
       " ('Ilove', 0.5702950954437256),\n",
       " ('affection', 0.5664337873458862),\n",
       " ('undying_love', 0.5547305345535278),\n",
       " ('absolutely_adore', 0.5536840558052063)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 24s 805ms/step - loss: 0.6902 - accuracy: 0.5327 - val_loss: 0.6797 - val_accuracy: 0.5717\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 23s 765ms/step - loss: 0.6411 - accuracy: 0.6553 - val_loss: 0.5975 - val_accuracy: 0.7135\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 22s 736ms/step - loss: 0.5066 - accuracy: 0.7806 - val_loss: 0.4431 - val_accuracy: 0.8120\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 21s 707ms/step - loss: 0.3461 - accuracy: 0.8653 - val_loss: 0.3605 - val_accuracy: 0.8425\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 22s 732ms/step - loss: 0.2520 - accuracy: 0.9034 - val_loss: 0.3285 - val_accuracy: 0.8613\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 24s 802ms/step - loss: 0.1995 - accuracy: 0.9301 - val_loss: 0.3124 - val_accuracy: 0.8658\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 21s 707ms/step - loss: 0.1395 - accuracy: 0.9593 - val_loss: 0.3225 - val_accuracy: 0.8688\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 21s 710ms/step - loss: 0.1034 - accuracy: 0.9700 - val_loss: 0.3577 - val_accuracy: 0.8601\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 21s 690ms/step - loss: 0.0700 - accuracy: 0.9854 - val_loss: 0.3515 - val_accuracy: 0.8632\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 21s 687ms/step - loss: 0.0466 - accuracy: 0.9939 - val_loss: 0.3647 - val_accuracy: 0.8662\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 21s 685ms/step - loss: 0.0297 - accuracy: 0.9972 - val_loss: 0.3859 - val_accuracy: 0.8661\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 21s 689ms/step - loss: 0.0211 - accuracy: 0.9991 - val_loss: 0.3990 - val_accuracy: 0.8644\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 21s 696ms/step - loss: 0.0145 - accuracy: 0.9993 - val_loss: 0.4185 - val_accuracy: 0.8642\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 21s 695ms/step - loss: 0.0109 - accuracy: 0.9995 - val_loss: 0.4321 - val_accuracy: 0.8643\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 21s 690ms/step - loss: 0.0082 - accuracy: 0.9996 - val_loss: 0.4450 - val_accuracy: 0.8644\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 21s 690ms/step - loss: 0.0066 - accuracy: 0.9997 - val_loss: 0.4623 - val_accuracy: 0.8643\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 21s 689ms/step - loss: 0.0052 - accuracy: 0.9999 - val_loss: 0.4733 - val_accuracy: 0.8641\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 21s 688ms/step - loss: 0.0042 - accuracy: 0.9999 - val_loss: 0.4840 - val_accuracy: 0.8639\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 21s 695ms/step - loss: 0.0033 - accuracy: 0.9999 - val_loss: 0.5067 - val_accuracy: 0.8640\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 22s 742ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 0.5318 - val_accuracy: 0.8638\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 6s - loss: 0.5974 - accuracy: 0.8510\n",
      "[0.5974054932594299, 0.8510000109672546]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
