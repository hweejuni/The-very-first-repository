{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic classification project\n",
    "\n",
    "## Content   \n",
    "\n",
    "&nbsp;&nbsp;&nbsp;**1.Aims and objectives**   \n",
    "&nbsp;&nbsp;&nbsp;**2.Literature review**   \n",
    "&nbsp;&nbsp;&nbsp;**3.Method**   \n",
    "&nbsp;&nbsp;&nbsp;**4.Result**   \n",
    "&nbsp;&nbsp;&nbsp;**5.Discussion and conclusion**   \n",
    "&nbsp;&nbsp;&nbsp;**6.Reference**\n",
    "\n",
    "\n",
    "\n",
    "## 1. Aims and objectives\n",
    "\n",
    "This project aims to grasp fundamentals of scikit-learn library, dataset analysis, classification, and evaluation of the result of classification. Scikit-learn provides small sets of standard datasets, for example boston house prices for regression and diabetes dataset for classification. In this project, three classification datasets, iris, wine, and breast cancer datasets, had been adopted and analysed, and the models which were trained with them was evaluated accordingly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Literature review\n",
    "### Scikit-learn   \n",
    "   \n",
    "Scikit-learn is a free machine learning library for python programming language. It involves commonly used classification, clustering, and regression algorithms such as Suppor Vector Machine(SVM), decision tree, random forest or K-means method. The library was designed to interact with Numpy and Scipy perform both supervised and unsupervised learning (see [Scikit-learn](https://scikit-learn.org/stable/))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and analyse datasets   \n",
    "\n",
    "Three classification datasets(hand written digits, wine, breast cancer) had been acquired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report will focus on wine classification. For full codes of the three practices, ssee [wine](https://github.com/hweejuni/The-very-first-repository/blob/master/Classifier_Project/Wine_Classification.ipynb), [handwritten digits](https://github.com/hweejuni/The-very-first-repository/blob/master/Classifier_Project/Handwritten_Letter_Classifier.ipynb), and [breast cancer](https://github.com/hweejuni/The-very-first-repository/blob/master/Classifier_Project/Breast_Cancer_Classifier.ipynb).   \n",
    "\n",
    "Loading the wine dataset, the samples and labels (targets) were assigned into 'wine_data' and 'wine_label' respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  178 \n",
      "Feature names:  ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline'] \n",
      "Label names:  ['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "wines = load_wine()\n",
    "\n",
    "wines_data = wines.data # assign the data\n",
    "wines_label = wines.target # assign the label\n",
    "\n",
    "\n",
    "print('Number of samples: ', len(wines.data), '\\nFeature names: ', wines.feature_names, '\\nLabel names: ', wines.target_names)\n",
    "#print(wines.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be observed above, the wine dataset has 178 samples, 3 classes, and 13 features. Knowing how the dataset constitues is salient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset partition   \n",
    "   \n",
    "The dataset needs to be divided into both training and test dataset. The splitting can be achieved with 'train_test_split' function and only 20 percent of the dataset was converted to the test set. Moreover, when it comes to partitioning samples, it must be randomly executed since unshuffled subsets could result in unwelcomed bias into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(wines_data, \n",
    "                                                   wines_label,\n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics\n",
    "   \n",
    "Evaluating the model is paramount importance in classification. Above all, an optimized classifier is obtained by correct selection of appropriate metric for the optimal solution [1]    \n",
    "##### i) Accuracy   \n",
    "Accuracy is one of the most commonly used metrices among the researchers.  \n",
    "\n",
    "$${Accuracy = \\frac{Number\\,of\\,correct\\, predictions}{Total\\, number\\, of\\, predictions\\, made}}$$  \n",
    "\n",
    "However, considering accuracy as the main evaluation metric will come with a number of limitations. Especially, [2] and [3] have well demonstrated how accuracy is not good at tackling imbalanced dataset.   \n",
    "   \n",
    "##### ii) Confusion matrix   \n",
    "Confusion matrix is a matrix that suitably summarises the performance of the algorithm. In particular, it is competent at representing where the model have been confused in predicting.   \n",
    "![Confusion matrix](./r4.jpg)   \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *Figure 1: Confusion Matrix*   \n",
    "    \n",
    "The four outputs in figure 1 represent significant milestones when evaluating the performance.\n",
    "- True Positive(TP): The number of correct predictions that the model predicted true as true.   \n",
    "- False Negative(FN): The number of incorrect predictions that the model predicted positive as negative.   \n",
    "- False Positive(FP): The number of incorrect predictions that the model predicted negative as positive.   \n",
    "- True Negative(TN): The number of correct predictions that hte model predicted negative as negative.   \n",
    "\n",
    "They are mathematically calculated so as to express another important indications.   \n",
    "- Recall(Sensitivity): Recall is a ratio of 'TP' to 'actual' positive samples.   \n",
    "   \n",
    "$${Recall = \\frac{TP}{TP+FN}}$$   \n",
    "\n",
    "- Specificity: Specificity is a ratio of 'TN' to 'actual' negative samples.   \n",
    "\n",
    "$${Specificity = \\frac{TN}{FP+TN}}$$   \n",
    "\n",
    "- Precision: Precision is a ratio of 'TP' to 'labelled' positive samples.   \n",
    "\n",
    "$${Precision = \\frac{TP}{TP+FP}}$$   \n",
    "\n",
    "- F1 score: F1 score is a ratio showing the balance between Precision and Recall. F1 score ranges between 0 and 1; 0 indicating a total failure and 1 to be perfect. Good F1 score means the model predicted low false positives and negatives.\n",
    "\n",
    "$${F1\\, score = 2*\\frac{Precision*Recall}{Precision+Recall}}$$   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Method   \n",
    "### Training the model   \n",
    "   \n",
    "Five prominent classification algorithms had been trained: Decision tree, Random forest, Support Vector Machine, Stochastic Gradient Descent, and Logistic Regression. Each algorithm asks for different syntax to call the classifier model.\n",
    "\n",
    "##### i) Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ii) Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iii) Support Vector Machine(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svm_model = svm.SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iv) Stochastic Gradient Descent Classifier(SGD Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_model = SGDClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### v) Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Result   \n",
    "\n",
    "For the results, see [wine](https://github.com/hweejuni/The-very-first-repository/blob/master/Classifier_Project/Wine_Classification.ipynb), [handwritten digits](https://github.com/hweejuni/The-very-first-repository/blob/master/Classifier_Project/Handwritten_Letter_Classifier.ipynb), and [breast cancer](https://github.com/hweejuni/The-very-first-repository/blob/master/Classifier_Project/Breast_Cancer_Classifier.ipynb).   \n",
    "\n",
    "Support Vector Machine(SVM) conducted the most correct performance, achieving approximately 99% accuracy in handwritten digit classification project. On the other hand, Random forest method is most accurate in both wine and breast cancer classification project, reaching 100% accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Discussion and conclusion   \n",
    "\n",
    "As a result, it can be thought that SVM is competent at dealing with large samples by comparison, whilst Random forest is good at less samples. The experiments were conducted in more uncomplicated fashion so that the models could be compared intuitively and straightforwardly. Other models should be more explored with different hyperparameters for larger number of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Reference   \n",
    "\n",
    "[1] H. M and S. M.N, \"A Review on Evaluation Metrics for Data Classification Evaluations\", International Journal of Data Mining & Knowledge Management Process, vol. 5, no. 2, pp. 01-11, 2015. Available: 10.5121/ijdkp.2015.5201 [Accessed 30 July 2020].   \n",
    "\n",
    "[2] R. Ranawana, and V. Palade, “Optimized precision-A new measure for classifier performance\n",
    "evaluation”, in Proc. of the IEEE World Congress on Evolutionary Computation (CEC 2006), 2006,\n",
    "pp. 2254-2261.    \n",
    "\n",
    "[3] S. W. Wilson, “Mining oblique data with XCS”, in P. L. Lanzi, W. Stolzmann and S. W. Wilson\n",
    "(Eds.) Advances in Learning Classifier Systems: Third Int. Workshop (IWLCS 2000), Berlin,\n",
    "Heidelberg: Springer-Verlag, 2001, pp. 283-290. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
