{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  178 \n",
      "Feature names:  ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline'] \n",
      "Label names:  ['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "wines = load_wine()\n",
    "#print(load_wine())\n",
    "\n",
    "wines_data = wines.data # assign the data\n",
    "wines_label = wines.target # assign the label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(wines_data, \n",
    "                                                   wines_label,\n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state = 7) # spliting train and test datasets in random and distributed fashion.\n",
    "print('Number of samples: ', len(wines.data), '\\nFeature names: ', wines.feature_names, '\\nLabel names: ', wines.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9444444444444444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      1.00      0.94        17\n",
      "           2       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.94      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Decision tree\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred_1 = decision_tree.predict(X_test)\n",
    "accuracy_1 = accuracy_score(y_test, y_pred_1)\n",
    "print(accuracy_1)\n",
    "print(classification_report(y_test, y_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Random forest\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred_2 = random_forest.predict(X_test)\n",
    "accuracy_2 = accuracy_score(y_test, y_pred_2)\n",
    "print(accuracy_2)\n",
    "print(classification_report(y_test, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6111111111111112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86         7\n",
      "           1       0.58      0.88      0.70        17\n",
      "           2       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.59      0.61      0.56        36\n",
      "weighted avg       0.55      0.61      0.54        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Support Vector Vachine (SVM)\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_3 = svm_model.predict(X_test)\n",
    "accuracy_3 = accuracy_score(y_test, y_pred_3)\n",
    "print(accuracy_3)\n",
    "print(classification_report(y_test, y_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6388888888888888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         7\n",
      "           1       0.71      0.88      0.79        17\n",
      "           2       1.00      0.08      0.15        12\n",
      "\n",
      "    accuracy                           0.64        36\n",
      "   macro avg       0.74      0.66      0.54        36\n",
      "weighted avg       0.77      0.64      0.55        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Stochastic Gradient Descent Classifier (SGD Classifier)\n",
    "sgd_model = SGDClassifier()\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred_4 = sgd_model.predict(X_test)\n",
    "accuracy_4 = accuracy_score(y_test, y_pred_4)\n",
    "print(accuracy_4)\n",
    "print(classification_report(y_test, y_pred_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9722222222222222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.97      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Logistic Regression\n",
    "logistic_model = LogisticRegression(max_iter=4000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_5 = logistic_model.predict(X_test)\n",
    "accuracy_5 = accuracy_score(y_test, y_pred_5)\n",
    "print(accuracy_5)\n",
    "print(classification_report(y_test, y_pred_5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
