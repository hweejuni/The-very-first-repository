{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이타 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import re    \n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수: 178009\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125110</th>\n",
       "      <td>You've asked a very good question.</td>\n",
       "      <td>Vous avez posé une très bonne question.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141496</th>\n",
       "      <td>You probably won't be able to do that.</td>\n",
       "      <td>Tu ne seras probablement pas capable de faire ça.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3524</th>\n",
       "      <td>He was wrong.</td>\n",
       "      <td>Il eut tort.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140374</th>\n",
       "      <td>That accident happened near his house.</td>\n",
       "      <td>Cet accident se produisit près de chez lui.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51962</th>\n",
       "      <td>We consider Tom honest.</td>\n",
       "      <td>Nous considérons Tom comme un honnête homme.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           eng  \\\n",
       "125110      You've asked a very good question.   \n",
       "141496  You probably won't be able to do that.   \n",
       "3524                             He was wrong.   \n",
       "140374  That accident happened near his house.   \n",
       "51962                  We consider Tom honest.   \n",
       "\n",
       "                                                      fra  \\\n",
       "125110            Vous avez posé une très bonne question.   \n",
       "141496  Tu ne seras probablement pas capable de faire ça.   \n",
       "3524                                         Il eut tort.   \n",
       "140374        Cet accident se produisit près de chez lui.   \n",
       "51962        Nous considérons Tom comme un honnête homme.   \n",
       "\n",
       "                                                       cc  \n",
       "125110  CC-BY 2.0 (France) Attribution: tatoeba.org #8...  \n",
       "141496  CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
       "3524    CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "140374  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "51962   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수:', len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91530</th>\n",
       "      <td>I see your cat in the garden.</td>\n",
       "      <td>Je vois votre chat dans le jardin.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71618</th>\n",
       "      <td>No child should go hungry.</td>\n",
       "      <td>Aucun enfant ne devrait avoir faim.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83111</th>\n",
       "      <td>He will be writing a letter.</td>\n",
       "      <td>Il écrira une lettre.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60418</th>\n",
       "      <td>Did anybody see anything?</td>\n",
       "      <td>Quiconque a-t-il vu quoi que ce soit ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60828</th>\n",
       "      <td>Even a child can do that.</td>\n",
       "      <td>Même un enfant peut faire ça.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 eng                                     fra\n",
       "91530  I see your cat in the garden.      Je vois votre chat dans le jardin.\n",
       "71618     No child should go hungry.     Aucun enfant ne devrait avoir faim.\n",
       "83111   He will be writing a letter.                   Il écrira une lettre.\n",
       "60418      Did anybody see anything?  Quiconque a-t-il vu quoi que ce soit ?\n",
       "60828      Even a child can do that.           Même un enfant peut faire ça."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[['eng', 'fra']][60000:93000]\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"You've got to help them.\", \"You've got to help them.\",\n",
       "       \"You've got to stop this.\", ..., \"Obviously, there's a problem.\",\n",
       "       'Oil is extracted from olives.', 'Old habits are hard to break.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_np_eng= lines['eng'].to_numpy()\n",
    "lines_np_fra= lines['fra'].to_numpy()\n",
    "lines_np_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리   \n",
    "\n",
    "### 구두점 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_token = '<start> '\n",
    "eos_token = ' <end>'\n",
    "\n",
    "def preprocess_line(line, plus_token = True):\n",
    "    # 소문자로 변경하기\n",
    "    line = line.lower().strip()\n",
    "    # 구두점(Punctuation)을 단어와 분리하기\n",
    "    line = re.sub(r\"([?.!,¿])\", r\" \\1 \", line)\n",
    "    line = re.sub(r'[\" \"]+', \" \", line)\n",
    "    line = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", line)\n",
    "\n",
    "    line = line.strip()\n",
    "    \n",
    "    if plus_token == True:\n",
    "        line = sos_token + line + eos_token\n",
    "    \n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 띄워쓰기 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):\n",
    "    tokenizer = Tokenizer(\n",
    "        num_words=7000,  \n",
    "        filters=' ',   \n",
    "        oov_token=\"<unk>\"  \n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)  \n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "\n",
    "    return tensor, tokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 영어 프랑스어 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_lines = []\n",
    "fra_lines = []\n",
    "\n",
    "# eng_lines.append(lines.eng.apply(lambda x : preprocess_line(x,plus_token = False)))\n",
    "# fra_lines.append(lines.fra.apply(lambda x : preprocess_line(x),))\n",
    "\n",
    "for eng, fra in zip(lines.eng, lines.fra):\n",
    "    if len(eng) == 0: continue\n",
    "    if len(fra) == 0: continue   \n",
    "        \n",
    "    eng_lines.append(preprocess_line(eng, plus_token = False))\n",
    "    fra_lines.append(preprocess_line(fra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(eng_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 8, 313, 36, 135, 4, 3],\n",
       " [2, 15, 115, 36, 135, 4, 3],\n",
       " [2, 15, 115, 159, 229, 12, 4, 3],\n",
       " [2, 8, 313, 159, 229, 12, 4, 3],\n",
       " [2, 15, 115, 1760, 50, 3],\n",
       " [2, 8, 313, 1760, 50, 3],\n",
       " [2, 15, 19, 52, 83, 27, 206, 4, 3],\n",
       " [2, 8, 19, 55, 83, 27, 206, 4, 3],\n",
       " [2, 8, 55, 47, 223, 4, 3],\n",
       " [2, 15, 52, 47, 223, 4, 3]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tensor, eng_tokenizer = tokenize(eng_lines)\n",
    "fra_tensor, fra_tokenizer = tokenize(fra_lines)\n",
    "fra_tensor[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input, target 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = eng_tensor\n",
    "# 종료 토큰 제거\n",
    "decoder_input = [[char for char in line if char != fra_tokenizer.word_index['<end>']] for line in fra_tensor]\n",
    "# 시작 토큰 제거\n",
    "decoder_target =[[char for char in line if char != fra_tokenizer.word_index['<start>']] for line in fra_tensor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### padding 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensor(tensor):\n",
    "    total_data_text = list(tensor)\n",
    "    num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "    max_tokens = max(num_tokens)\n",
    "#     max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "    maxlen = int(max_tokens)\n",
    "    tensor = pad_sequences(tensor, padding='post', maxlen=maxlen)  \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 11)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 20)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 20)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = pad_tensor(encoder_input)\n",
    "decoder_input = pad_tensor(decoder_input)\n",
    "decoder_target = pad_tensor(decoder_target)\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index)+1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index)+1\n",
    "\n",
    "max_eng_seq_len = encoder_input.shape[1]\n",
    "max_fra_seq_len = decoder_input.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n",
      "영어 단어장의 크기 : 5932\n",
      "프랑스어 단어장의 크기 : 8507\n",
      "영어 시퀀스의 최대 길이 11\n",
      "프랑스어 시퀀스의 최대 길이 20\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 수 :',len(lines))\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train, test dataset 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 11)\n",
      "(30000, 20)\n",
      "(30000, 20)\n",
      "(3000, 11)\n",
      "(3000, 20)\n",
      "(3000, 20)\n"
     ]
    }
   ],
   "source": [
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print(encoder_input_train.shape)\n",
    "print(decoder_input_train.shape)\n",
    "print(decoder_target_train.shape)\n",
    "print(encoder_input_test.shape)\n",
    "print(decoder_input_test.shape)\n",
    "print(decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 임베딩 층(Embedding layer) 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 512\n",
    "hidden_size = 512\n",
    "# 인코더에서 사용할 임베딩 층 사용 예시\n",
    "encoder_inputs = Input(shape=(None, ), name='encoder_input')\n",
    "enc_emb =  Embedding(eng_vocab_size, embedding_size,\n",
    "                    input_length=max_eng_seq_len)(encoder_inputs)\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb)\n",
    "encoder_lstm = LSTM(hidden_size, dropout = 0.5, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, ), name='decoder_input')\n",
    "dec_emb =  Embedding(fra_vocab_size, embedding_size)(decoder_inputs)\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "decoder_lstm = LSTM(hidden_size, dropout = 0.5, return_sequences = True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking, initial_state = encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 512)    3037184     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 512)    4355584     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 512)    0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 512)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 512), (None, 2099200     masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 512),  2099200     masking_1[0][0]                  \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8507)   4364091     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 15,955,259\n",
      "Trainable params: 15,955,259\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "938/938 [==============================] - 299s 319ms/step - loss: 1.7885 - val_loss: 1.4908\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 301s 320ms/step - loss: 1.3508 - val_loss: 1.2754\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 306s 326ms/step - loss: 1.1666 - val_loss: 1.1476\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 284s 303ms/step - loss: 1.0398 - val_loss: 1.0628\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 270s 288ms/step - loss: 0.9427 - val_loss: 1.0099\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 270s 287ms/step - loss: 0.8662 - val_loss: 0.9670\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 269s 287ms/step - loss: 0.8051 - val_loss: 0.9379\n",
      "Epoch 8/50\n",
      "938/938 [==============================] - 269s 287ms/step - loss: 0.7542 - val_loss: 0.9186\n",
      "Epoch 9/50\n",
      "938/938 [==============================] - 269s 287ms/step - loss: 0.7113 - val_loss: 0.9110\n",
      "Epoch 10/50\n",
      "938/938 [==============================] - 270s 287ms/step - loss: 0.6868 - val_loss: 0.9115\n",
      "Epoch 11/50\n",
      "938/938 [==============================] - 270s 287ms/step - loss: 0.6627 - val_loss: 0.9067\n",
      "Epoch 12/50\n",
      "938/938 [==============================] - 269s 287ms/step - loss: 0.6420 - val_loss: 0.9082\n",
      "Epoch 13/50\n",
      "938/938 [==============================] - 269s 287ms/step - loss: 0.6291 - val_loss: 0.9078\n",
      "Epoch 14/50\n",
      "938/938 [==============================] - 269s 287ms/step - loss: 0.6183 - val_loss: 0.9027\n",
      "Epoch 15/50\n",
      "938/938 [==============================] - 269s 287ms/step - loss: 0.6036 - val_loss: 0.9023\n",
      "Epoch 16/50\n",
      "938/938 [==============================] - 269s 287ms/step - loss: 0.5861 - val_loss: 0.8984\n",
      "Epoch 17/50\n",
      "938/938 [==============================] - 269s 287ms/step - loss: 0.5754 - val_loss: 0.9060\n",
      "Epoch 18/50\n",
      "938/938 [==============================] - 270s 288ms/step - loss: 0.5670 - val_loss: 0.9037\n",
      "Epoch 19/50\n",
      "938/938 [==============================] - 269s 287ms/step - loss: 0.5551 - val_loss: 0.9035\n",
      "Epoch 20/50\n",
      "938/938 [==============================] - 270s 287ms/step - loss: 0.5463 - val_loss: 0.9019\n",
      "Epoch 21/50\n",
      "938/938 [==============================] - 270s 287ms/step - loss: 0.5395 - val_loss: 0.9024\n",
      "Epoch 22/50\n",
      "938/938 [==============================] - 270s 287ms/step - loss: 0.5313 - val_loss: 0.9011\n",
      "Epoch 23/50\n",
      "938/938 [==============================] - 270s 287ms/step - loss: 0.5239 - val_loss: 0.8992\n",
      "Epoch 24/50\n",
      "938/938 [==============================] - 269s 287ms/step - loss: 0.5137 - val_loss: 0.8842\n",
      "Epoch 25/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.5014 - val_loss: 0.8864\n",
      "Epoch 26/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.5009 - val_loss: 0.8900\n",
      "Epoch 27/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.4960 - val_loss: 0.8862\n",
      "Epoch 28/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.4907 - val_loss: 0.8867\n",
      "Epoch 29/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.4861 - val_loss: 0.8804\n",
      "Epoch 30/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.4797 - val_loss: 0.8781\n",
      "Epoch 31/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.4728 - val_loss: 0.8785\n",
      "Epoch 32/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.4669 - val_loss: 0.8779\n",
      "Epoch 33/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.4624 - val_loss: 0.8761\n",
      "Epoch 34/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.4600 - val_loss: 0.8734\n",
      "Epoch 35/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.4572 - val_loss: 0.8745\n",
      "Epoch 36/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.4551 - val_loss: 0.8743\n",
      "Epoch 37/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.4524 - val_loss: 0.8734\n",
      "Epoch 38/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.4507 - val_loss: 0.8714\n",
      "Epoch 39/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.4475 - val_loss: 0.8724\n",
      "Epoch 40/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.4447 - val_loss: 0.8731\n",
      "Epoch 41/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.4408 - val_loss: 0.8717\n",
      "Epoch 42/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.4357 - val_loss: 0.8712\n",
      "Epoch 43/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.4321 - val_loss: 0.8705\n",
      "Epoch 44/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.4279 - val_loss: 0.8724\n",
      "Epoch 45/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.4241 - val_loss: 0.8743\n",
      "Epoch 46/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.4229 - val_loss: 0.8754\n",
      "Epoch 47/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.4200 - val_loss: 0.8717\n",
      "Epoch 48/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.4172 - val_loss: 0.8761\n",
      "Epoch 49/50\n",
      "938/938 [==============================] - 268s 286ms/step - loss: 0.4150 - val_loss: 0.8777\n",
      "Epoch 50/50\n",
      "938/938 [==============================] - 268s 285ms/step - loss: 0.4137 - val_loss: 0.8762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9b7297b150>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input_train, decoder_input_train], \n",
    "          y=decoder_target_train, \n",
    "          validation_data = ([encoder_input_test, decoder_input_test], \n",
    "                             decoder_target_test),\n",
    "          batch_size=32, \n",
    "          epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 512)         3037184   \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 512), (None, 512) 2099200   \n",
      "=================================================================\n",
      "Total params: 5,136,384\n",
      "Trainable params: 5,136,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(embedding_size,))\n",
    "decoder_state_input_c = Input(shape=(embedding_size,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2 = Embedding(fra_vocab_size, embedding_size)(decoder_inputs)\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state = decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_outputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 512)    4355584     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 512),  2099200     embedding_2[0][0]                \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8507)   4364091     lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 10,818,875\n",
      "Trainable params: 10,818,875\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs2] + decoder_states2)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <start>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = fra2idx['<start>']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '<end>' or\n",
    "           len(decoded_sentence) > max_fra_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2src(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + idx2eng[i]+' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2tar(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=fra2idx['<start>']) and i!=fra2idx['<end>']):\n",
    "            temp = temp + idx2fra[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: give me a minute , please . \n",
      "정답 문장: donnez moi une minute , s il vous pla t . \n",
      "번역기가 번역한 문장:  donne moi une , de \n",
      "-----------------------------------\n",
      "입력 문장: lightning struck the tower . \n",
      "정답 문장: l clair frappa la tour . \n",
      "번역기가 번역한 문장:  la la la la la . . \n",
      "-----------------------------------\n",
      "입력 문장: what are you sorry about ? \n",
      "정답 문장: pourquoi tes vous d sol e ? \n",
      "번역기가 번역한 문장:  pourquoi es en d d \n",
      "-----------------------------------\n",
      "입력 문장: the bucket is full of water . \n",
      "정답 문장: le seau est rempli d eau . \n",
      "번역기가 번역한 문장:  le est e d de de de \n",
      "-----------------------------------\n",
      "입력 문장: we must clean our classroom . \n",
      "정답 문장: nous devons nettoyer notre salle de classe . \n",
      "번역기가 번역한 문장:  nous nous nous notr\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [7,159,234,987,1987]:\n",
    "    input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', seq2src(encoder_input_test[seq_index]))\n",
    "    print('정답 문장:', seq2tar(decoder_input_test[seq_index]))\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
