{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rock-Paper-Scissor image classifier project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Aims and objectives\n",
    "2. Method\n",
    "3. Result\n",
    "4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Aims and objectives\n",
    "    \n",
    "    The focus of this project is on classifying three options of a hand game called 'Rock paper scissors', using tensorflow in python environment. The option consists of the three handsigns: Rock, paper, and scissors. In order to achieve the main objective, the project is divided into several parts:\n",
    "    \n",
    "   **stage 1**: Build python environment for using tensorflow, image dataset, etc. The appropriate libraries and packages are required.\n",
    "   \n",
    "   **stage 2**: Data acquisition. This stage includes taking pictures, and gathering images from other sources for both train and test data.\n",
    "   **stage 3**: Design the model. The class and model chosen for the training produce two 2-dimensional convolutional layers and two dense layers.\n",
    "   **stage 4**: Train the model using the train dataset.\n",
    "   **stage 5**: Validate the result using the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Method\n",
    "\n",
    " ### Data acquisition\n",
    "    \n",
    "    Some machine learning algorithm requires input dataset to predict the output. The training and testing data for this project will be image files and collected by 1. directly taking pictures and 2. downloading from other resources. First, visual or audible project resources such as image, video, or pose can be trained on the website provided by [Teachable Machine](https://teachablemachine.withgoogle.com/). 100 pictures had been taken using the laptop webcam.\n",
    "![Image](/home/aiffel0042/Desktop/12.png \"Taking pictures on Teachable Machine\")\n",
    "    \n",
    "[Tensorflow rock-paper-scissors datasets](https://www.tensorflow.org/datasets/catalog/rock_paper_scissors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Hwijun",
   "language": "python",
   "name": "hwijun"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
